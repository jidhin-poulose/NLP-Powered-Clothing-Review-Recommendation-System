{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knle951aueBM"
      },
      "source": [
        "# Assignment 2: Milestone I Natural Language Processing\n",
        "## Task 2&3\n",
        "#### Student Name: Jidhin Poulose\n",
        "#### Student ID: s4023503\n",
        "\n",
        "\n",
        "Environment: Python 3 and Jupyter notebook\n",
        "\n",
        "Libraries used: please include all the libraries you used in your assignment, e.g.,:\n",
        "* pandas\n",
        "* re\n",
        "* numpy\n",
        "\n",
        "## Introduction\n",
        "You should give a brief information of this assessment task here.\n",
        "\n",
        "<span style=\"color: red\"> Note that this is a sample notebook only. You will need to fill in the proper markdown and code blocks. You might also want to make necessary changes to the structure to meet your own needs. Note also that any generic comments written in this notebook are to be removed and replace with your own words.</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1LnzqqSueBP"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0bFOFVYueBR"
      },
      "outputs": [],
      "source": [
        "# Code to import libraries as you need in this assessment, e.g.,\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from gensim.models import KeyedVectors\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the csv file\n",
        "data = pd.read_csv('processed.csv')"
      ],
      "metadata": {
        "id": "u8Fb_7WtUjG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "IVylHzCqUm6l",
        "outputId": "bde47102-e565-4c15-f9ad-5920bbce5b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Clothing ID  Age                    Title  \\\n",
              "0         1077   60  Some major design flaws   \n",
              "1         1049   50         My favorite buy!   \n",
              "2          847   47         Flattering shirt   \n",
              "3         1080   49  Not for the very petite   \n",
              "4          858   39     Cagrcoal shimmer fun   \n",
              "\n",
              "                                         Review Text  Rating  Recommended IND  \\\n",
              "0  i had such high hopes for this dress and reall...       3                0   \n",
              "1  i love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
              "2  this shirt is very flattering to all due to th...       5                1   \n",
              "3  i love tracy reese dresses, but this one is no...       2                0   \n",
              "4  i aded this in my basket at hte last mintue to...       5                1   \n",
              "\n",
              "   Positive Feedback Count   Division Name Department Name Class Name  \\\n",
              "0                        0         General         Dresses    Dresses   \n",
              "1                        0  General Petite         Bottoms      Pants   \n",
              "2                        6         General            Tops    Blouses   \n",
              "3                        4         General         Dresses    Dresses   \n",
              "4                        1  General Petite            Tops      Knits   \n",
              "\n",
              "                                    Processed_Review  \n",
              "0  high hopes wanted work initially petite usual ...  \n",
              "1      jumpsuit fun flirty fabulous time compliments  \n",
              "2  shirt due adjustable front tie length leggings...  \n",
              "3  tracy reese dresses petite feet tall brand pre...  \n",
              "4  basket hte person store pick teh pale hte gorg...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e649f2ef-bbe8-47cd-978d-af374de85bc8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "      <th>Processed_Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>i had such high hopes for this dress and reall...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>high hopes wanted work initially petite usual ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>i love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "      <td>jumpsuit fun flirty fabulous time compliments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>this shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "      <td>shirt due adjustable front tie length leggings...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1080</td>\n",
              "      <td>49</td>\n",
              "      <td>Not for the very petite</td>\n",
              "      <td>i love tracy reese dresses, but this one is no...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>tracy reese dresses petite feet tall brand pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>858</td>\n",
              "      <td>39</td>\n",
              "      <td>Cagrcoal shimmer fun</td>\n",
              "      <td>i aded this in my basket at hte last mintue to...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "      <td>basket hte person store pick teh pale hte gorg...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e649f2ef-bbe8-47cd-978d-af374de85bc8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e649f2ef-bbe8-47cd-978d-af374de85bc8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e649f2ef-bbe8-47cd-978d-af374de85bc8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4a1776d7-addf-4521-9414-2c9bdebbfe89\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a1776d7-addf-4521-9414-2c9bdebbfe89')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4a1776d7-addf-4521-9414-2c9bdebbfe89 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 19662,\n  \"fields\": [\n    {\n      \"column\": \"Clothing ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 200,\n        \"min\": 1,\n        \"max\": 1205,\n        \"num_unique_values\": 1095,\n        \"samples\": [\n          1151,\n          1099,\n          204\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 18,\n        \"max\": 99,\n        \"num_unique_values\": 77,\n        \"samples\": [\n          39,\n          83,\n          32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13983,\n        \"samples\": [\n          \"Can't miss classic!!\",\n          \"Fun and unusial\",\n          \"Fantastic sweater\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19656,\n        \"samples\": [\n          \"i recently bought this dress and wore it once. i really liked it! it was comfy, cute and fit well. but... then i washed it. i followed the washing instructions exactly, but now it looks more like a shirt than a dress and it's completely unwearable. i'm super disappointed because i thought this dress would be a wardrobe staple this summer.\",\n          \"this green sweater is solo pretty . i wanted it from the moment i saw it. pretty layers on the bottom make it so unique!\",\n          \"i tried this jacket on in store, both m & l. both seemed to pull a little at waist/pocket (notice the raised pleat on the closeup. i ordered xl on line. it fits better but still seems to fit like the other two when fastened. snaps seem to be misplaced. on the plus side, the style is cute and there is brown (taupe) mixed in with the grey which is more flattering to brownettes. there isn't much difference in sizing of all three. i am not sure whether this is a keeper. open, it is fine and casual;\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recommended IND\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Positive Feedback Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 79,\n        \"samples\": [\n          37,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Division Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"General\",\n          \"General Petite\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Department Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Dresses\",\n          \"Bottoms\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Dresses\",\n          \"Layering\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Processed_Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19630,\n        \"samples\": [\n          \"pattern worn things bit short long torso\",\n          \"jeans pair sizes re-ordered pair run sizes larger normal achieve feel skinny jeans closet\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "ZtF8OBowcE6t",
        "outputId": "2a071135-35fc-444f-b7ef-8e7023ef16d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Clothing ID                 0\n",
              "Age                         0\n",
              "Title                       0\n",
              "Review Text                 0\n",
              "Rating                      0\n",
              "Recommended IND             0\n",
              "Positive Feedback Count     0\n",
              "Division Name               0\n",
              "Department Name             0\n",
              "Class Name                  0\n",
              "Processed_Review           10\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Clothing ID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Title</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Review Text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rating</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recommended IND</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Division Name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Department Name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class Name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Processed_Review</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna()"
      ],
      "metadata": {
        "id": "pVqCwQ89dN90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "MzH31y7PdcRw",
        "outputId": "1e799b0f-c16a-473b-f52a-581ce5ea6b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Clothing ID                0\n",
              "Age                        0\n",
              "Title                      0\n",
              "Review Text                0\n",
              "Rating                     0\n",
              "Recommended IND            0\n",
              "Positive Feedback Count    0\n",
              "Division Name              0\n",
              "Department Name            0\n",
              "Class Name                 0\n",
              "Processed_Review           0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Clothing ID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Title</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Review Text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rating</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recommended IND</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Division Name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Department Name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class Name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Processed_Review</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tk_reviews = data['Processed_Review']"
      ],
      "metadata": {
        "id": "RePgueZDVSw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tk_reviews = tk_reviews.to_list()"
      ],
      "metadata": {
        "id": "_8hmzokWVun6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tk_reviews[1:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmUOKK42VXU7",
        "outputId": "b6570cea-0b67-4f39-f1b1-2ab5c1f77a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jumpsuit fun flirty fabulous time compliments',\n",
              " 'shirt due adjustable front tie length leggings sleeveless pairs cardigan shirt']"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(tk_reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB_mnSe-WTZv",
        "outputId": "f09318cb-84b2-4032-8fac-5ee5f6cc4d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tk_reviews = [review.split(\" \") for review in tk_reviews if review]\n"
      ],
      "metadata": {
        "id": "5SkeSgtTVlPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tk_reviews[1:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZcdZk5Edm0f",
        "outputId": "f3f2105d-3ace-490c-c7f7-db9e61882f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['jumpsuit', 'fun', 'flirty', 'fabulous', 'time', 'compliments'],\n",
              " ['shirt',\n",
              "  'due',\n",
              "  'adjustable',\n",
              "  'front',\n",
              "  'tie',\n",
              "  'length',\n",
              "  'leggings',\n",
              "  'sleeveless',\n",
              "  'pairs',\n",
              "  'cardigan',\n",
              "  'shirt']]"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the vocabulary\n",
        "def load_vocab(vocab_file):\n",
        "    with open(vocab_file, 'r') as f:\n",
        "        vocab = {line.strip().split(':')[0]: int(line.strip().split(':')[1]) for line in f}\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "ADYxrTMymECU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_file = 'vocab.txt'\n",
        "vocab = load_vocab(vocab_file)"
      ],
      "metadata": {
        "id": "2fUqguJUmG_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2UGM_-3ueBS"
      },
      "source": [
        "## Task 2. Generating Feature Representations for Clothing Items Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWkWBY4kueBS"
      },
      "outputs": [],
      "source": [
        "# binding the words together for each review\n",
        "joined_reviews = [' '.join(review) for review in tk_reviews]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists('glove.6B.zip'):\n",
        "    print(\"Downloading GloVe embeddings...\")\n",
        "    !wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -o -q glove.6B.zip -d glove"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVCwRSe_xnvR",
        "outputId": "93b20eae-31c6-41ef-c068-9a0a053bc112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading GloVe embeddings...\n",
            "--2024-10-01 04:47:59--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-10-01 04:47:59--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M   885KB/s    in 16m 26s \n",
            "\n",
            "2024-10-01 05:04:26 (854 KB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the GloVe pre-trained embeddings file\n",
        "from gensim.models import KeyedVectors\n",
        "with open('glove/glove.6B.50d.txt') as f:\n",
        "    keys, weights = [], []\n",
        "    for l in f:\n",
        "      # Split each line into the word and its vector representation\n",
        "      k, v = l.split(maxsplit=1)\n",
        "      keys.append(k)\n",
        "      # Convert the vector string to a numpy array and add to weights list\n",
        "      weights.append(np.fromstring(v, sep=' '))\n",
        "# Create a KeyedVectors object to store the embeddings\n",
        "# The vector size is determined by the shape of the first weight vector\n",
        "glove_embeddings = KeyedVectors(weights[0].shape[0], count=len(keys))\n",
        "glove_embeddings.add_vectors(keys, weights)\n",
        "preTGloVe_wv = glove_embeddings"
      ],
      "metadata": {
        "id": "r5RIPkrtQSML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Found %s word vectors.\" % len(preTGloVe_wv))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d83V4e8-QfrD",
        "outputId": "42d19c66-9c32-43b7-ee02-3f413b13f5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 800000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Count vectors representation**"
      ],
      "metadata": {
        "id": "c3Hwlk2vnmzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize CountVectorizer with the existing vocabulary\n",
        "cVectorizer = CountVectorizer(analyzer=\"word\", vocabulary=vocab)\n",
        "count_features = cVectorizer.fit_transform(joined_reviews)  # Generate count features\n",
        "count_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOQ_QFnRrS2k",
        "outputId": "7c47de90-d366-4bfd-a4f3-0d48cd61c715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19652, 7529)"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to write vector file (modified to include webindex)\n",
        "def write_vectorFile_with_index(data_features, filename, webindices):\n",
        "  # Get the number of rows (documents) in the data_features matrix\n",
        "  num = data_features.shape[0]\n",
        "  with open(filename, 'w') as out_file:\n",
        "    # Iterate through each row (document) in the data_features matrix\n",
        "    for a_ind in range(0, num):\n",
        "        out_file.write(f\"#{webindices[a_ind]},\")\n",
        "        # Iterate through non-zero elements in the current row\n",
        "        # This is efficient for sparse matrices\n",
        "        for f_ind in data_features[a_ind].nonzero()[1]:\n",
        "          # Get the value at the current position and convert to int\n",
        "          value = int(data_features[a_ind, f_ind])\n",
        "          out_file.write(f\"{f_ind}:{value},\")\n",
        "        out_file.write('\\n')"
      ],
      "metadata": {
        "id": "NBw_rYONnijX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Unweighted (binary) vector representation using GloVe**"
      ],
      "metadata": {
        "id": "ytxisYcmohRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize CountVectorizer with binary=True\n",
        "bVectorizer = CountVectorizer(analyzer=\"word\", binary=True, vocabulary=vocab)\n",
        "# Generate binary features\n",
        "binary_features = bVectorizer.fit_transform(joined_reviews)\n",
        "binary_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdeCQLe5p_86",
        "outputId": "64bb9fb4-d86d-43db-db10-1c2dc841b321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19652, 7529)"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate unweighted document vectors\n",
        "def unweighted_docvecs(embeddings, binary_features, docs):\n",
        "  # Initialize a zero matrix to store document vectors\n",
        "  vecs = np.zeros((len(docs), embeddings.vector_size))\n",
        "  for i, doc in enumerate(docs):\n",
        "    # Filter out terms that are not in the embedding vocabulary\n",
        "    valid_keys = [term for term in doc if term in embeddings.key_to_index]\n",
        "    # Create binary weights: 1 if the term is present in the document, 0 otherwise\n",
        "    binary_weights = [1 if binary_features[i, vocab[term]] > 0 else 0 for term in valid_keys]\n",
        "    # Multiply each term's embedding by its binary weight\n",
        "    weighted = [embeddings[term] * w for term, w in zip(valid_keys, binary_weights)]\n",
        "    # Sum up all the weighted embeddings to get the document vector\n",
        "    docvec = np.sum(weighted, axis=0)\n",
        "    # Store the document vector in the results matrix\n",
        "    vecs[i,:] = docvec\n",
        "  return vecs"
      ],
      "metadata": {
        "id": "U06LJ731qG3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate unweighted document vectors\n",
        "unweighted_preTGloVe_dvs = unweighted_docvecs(preTGloVe_wv, binary_features, tk_reviews)"
      ],
      "metadata": {
        "id": "k2-Kp7-lqrc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unweighted_preTGloVe_dvs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EChdR1mZniWw",
        "outputId": "057a6b0d-4478-490a-ba96-09d746175f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.57157302, -3.96359205,  3.31884074, ..., -0.23908034,\n",
              "         2.97417307, -2.44539618],\n",
              "       [-2.34051514,  1.39787209, -4.70805264, ..., -1.65546536,\n",
              "         0.38116995,  1.65550005],\n",
              "       [-5.53618002,  3.77994132, -2.72567987, ..., -6.70081997,\n",
              "        -1.06155181, -4.32599688],\n",
              "       ...,\n",
              "       [ 1.12529898, -0.69280398,  0.26605999, ..., -1.41801202,\n",
              "        -0.11023009,  2.23825979],\n",
              "       [ 2.91901064,  3.47800589,  1.67871833, ..., -4.15545177,\n",
              "        -2.15171194,  2.47598886],\n",
              "       [ 1.30052102,  0.42059994, -5.66381025, ..., -0.34029651,\n",
              "         1.61652899,  3.62967396]])"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TF-IDF Vector Represenation**"
      ],
      "metadata": {
        "id": "XWnzmzOwndPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_vocIndex(voc_fname):\n",
        "  with open(voc_fname) as vocf:\n",
        "    voc_Ind = [l.split(':') for l in vocf.read().splitlines()]\n",
        "  return {int(vi[1]):vi[0] for vi in voc_Ind}\n",
        "\n",
        "# Generates the w_index:word dictionary\n",
        "voc_fname = './vocab.txt'\n",
        "voc_dict = gen_vocIndex(voc_fname)\n",
        "voc_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77GVe2gUxnqi",
        "outputId": "bc06331d-4da2-4851-8dd7-c912c9d6d80d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'a-cup',\n",
              " 1: 'a-flutter',\n",
              " 2: 'a-frame',\n",
              " 3: 'a-kind',\n",
              " 4: 'a-line',\n",
              " 5: 'a-lines',\n",
              " 6: 'a-symmetric',\n",
              " 7: 'aa',\n",
              " 8: 'ab',\n",
              " 9: 'abbey',\n",
              " 10: 'abby',\n",
              " 11: 'abdomen',\n",
              " 12: 'ability',\n",
              " 13: 'abnormally',\n",
              " 14: 'abo',\n",
              " 15: 'abou',\n",
              " 16: 'above-the',\n",
              " 17: 'abroad',\n",
              " 18: 'abs',\n",
              " 19: 'absolute',\n",
              " 20: 'absolutely',\n",
              " 21: 'absolutley',\n",
              " 22: 'absolutly',\n",
              " 23: 'abstract',\n",
              " 24: 'absurd',\n",
              " 25: 'abt',\n",
              " 26: 'abundance',\n",
              " 27: 'ac',\n",
              " 28: 'accent',\n",
              " 29: 'accented',\n",
              " 30: 'accenting',\n",
              " 31: 'accents',\n",
              " 32: 'accentuate',\n",
              " 33: 'accentuated',\n",
              " 34: 'accentuates',\n",
              " 35: 'accentuating',\n",
              " 36: 'accept',\n",
              " 37: 'acceptable',\n",
              " 38: 'accepted',\n",
              " 39: 'access',\n",
              " 40: 'accessories',\n",
              " 41: 'accessorize',\n",
              " 42: 'accessorized',\n",
              " 43: 'accessorizing',\n",
              " 44: 'accessory',\n",
              " 45: 'accident',\n",
              " 46: 'accidental',\n",
              " 47: 'accidentally',\n",
              " 48: 'accommodate',\n",
              " 49: 'accommodated',\n",
              " 50: 'accommodates',\n",
              " 51: 'accommodating',\n",
              " 52: 'accomodate',\n",
              " 53: 'accompanying',\n",
              " 54: 'accomplish',\n",
              " 55: 'accordian',\n",
              " 56: 'account',\n",
              " 57: 'accurate',\n",
              " 58: 'accurately',\n",
              " 59: 'acetate',\n",
              " 60: 'achieve',\n",
              " 61: 'acrylic',\n",
              " 62: 'act',\n",
              " 63: 'action',\n",
              " 64: 'active',\n",
              " 65: 'activewear',\n",
              " 66: 'activities',\n",
              " 67: 'acts',\n",
              " 68: 'actual',\n",
              " 69: 'actuality',\n",
              " 70: 'ad',\n",
              " 71: 'ada',\n",
              " 72: 'add',\n",
              " 73: 'add-on',\n",
              " 74: 'added',\n",
              " 75: 'addict',\n",
              " 76: 'addicted',\n",
              " 77: 'adding',\n",
              " 78: 'addition',\n",
              " 79: 'additional',\n",
              " 80: 'additionally',\n",
              " 81: 'address',\n",
              " 82: 'adds',\n",
              " 83: 'adequate',\n",
              " 84: 'adequately',\n",
              " 85: 'adjust',\n",
              " 86: 'adjustable',\n",
              " 87: 'adjusted',\n",
              " 88: 'adjusting',\n",
              " 89: 'adjustment',\n",
              " 90: 'adjustments',\n",
              " 91: 'admire',\n",
              " 92: 'admired',\n",
              " 93: 'admiring',\n",
              " 94: 'admit',\n",
              " 95: 'admittedly',\n",
              " 96: 'adn',\n",
              " 97: 'ador',\n",
              " 98: 'adorable',\n",
              " 99: 'adore',\n",
              " 100: 'adored',\n",
              " 101: 'ads',\n",
              " 102: 'adult',\n",
              " 103: 'adults',\n",
              " 104: 'advantage',\n",
              " 105: 'advantages',\n",
              " 106: 'adventure',\n",
              " 107: 'advertised',\n",
              " 108: 'advice',\n",
              " 109: 'advise',\n",
              " 110: 'advised',\n",
              " 111: 'aesthetic',\n",
              " 112: 'aesthetically',\n",
              " 113: 'aesthetics',\n",
              " 114: 'affair',\n",
              " 115: 'affect',\n",
              " 116: 'affected',\n",
              " 117: 'affects',\n",
              " 118: 'afford',\n",
              " 119: 'affordable',\n",
              " 120: 'aforementioned',\n",
              " 121: 'afraid',\n",
              " 122: 'afternoon',\n",
              " 123: 'afterward',\n",
              " 124: 'ag',\n",
              " 125: \"ag's\",\n",
              " 126: 'age',\n",
              " 127: 'age-appropriate',\n",
              " 128: 'aged',\n",
              " 129: 'ages',\n",
              " 130: 'aggressive',\n",
              " 131: 'agin',\n",
              " 132: 'ago',\n",
              " 133: 'agree',\n",
              " 134: 'agreed',\n",
              " 135: 'agreement',\n",
              " 136: 'ags',\n",
              " 137: 'ah',\n",
              " 138: 'ahd',\n",
              " 139: 'ahead',\n",
              " 140: 'ahhh',\n",
              " 141: 'ahs',\n",
              " 142: 'ahve',\n",
              " 143: 'air',\n",
              " 144: 'air-dried',\n",
              " 145: 'air-drying',\n",
              " 146: 'airiness',\n",
              " 147: 'airing',\n",
              " 148: 'airplanes',\n",
              " 149: 'airport',\n",
              " 150: 'airy',\n",
              " 151: 'aize',\n",
              " 152: 'aka',\n",
              " 153: 'akemi',\n",
              " 154: 'al',\n",
              " 155: 'alas',\n",
              " 156: 'alaska',\n",
              " 157: 'albeit',\n",
              " 158: 'alexandria',\n",
              " 159: 'align',\n",
              " 160: 'aligned',\n",
              " 161: 'alike',\n",
              " 162: 'aline',\n",
              " 163: 'alittle',\n",
              " 164: 'all-around',\n",
              " 165: 'all-in',\n",
              " 166: 'all-over',\n",
              " 167: 'alley',\n",
              " 168: 'allison',\n",
              " 169: 'allover',\n",
              " 170: 'allowed',\n",
              " 171: 'allowing',\n",
              " 172: 'allusion',\n",
              " 173: 'alot',\n",
              " 174: 'alpaca',\n",
              " 175: 'alright',\n",
              " 176: 'als',\n",
              " 177: 'alter',\n",
              " 178: 'alteration',\n",
              " 179: 'alterations',\n",
              " 180: 'altered',\n",
              " 181: 'altering',\n",
              " 182: 'alternate',\n",
              " 183: 'alternations',\n",
              " 184: 'alternative',\n",
              " 185: 'altho',\n",
              " 186: 'altogether',\n",
              " 187: 'amadi',\n",
              " 188: 'amalfi',\n",
              " 189: 'amazed',\n",
              " 190: 'amazing',\n",
              " 191: 'amazingly',\n",
              " 192: 'amazon',\n",
              " 193: 'ambiguous',\n",
              " 194: 'amd',\n",
              " 195: 'american',\n",
              " 196: 'amount',\n",
              " 197: 'amounts',\n",
              " 198: 'amp',\n",
              " 199: 'ample',\n",
              " 200: 'amply',\n",
              " 201: 'amterial',\n",
              " 202: 'anatomy',\n",
              " 203: 'and-go',\n",
              " 204: 'angel',\n",
              " 205: 'angeles',\n",
              " 206: 'angle',\n",
              " 207: 'angled',\n",
              " 208: 'angles',\n",
              " 209: 'angora',\n",
              " 210: 'animal',\n",
              " 211: 'animals',\n",
              " 212: 'ankle',\n",
              " 213: 'ankle-length',\n",
              " 214: 'ankles',\n",
              " 215: \"ann's\",\n",
              " 216: 'anna',\n",
              " 217: 'anniversary',\n",
              " 218: 'annoyance',\n",
              " 219: 'annoyed',\n",
              " 220: 'annoying',\n",
              " 221: 'anorak',\n",
              " 222: 'ans',\n",
              " 223: 'answer',\n",
              " 224: 'ant',\n",
              " 225: 'anth',\n",
              " 226: 'anther',\n",
              " 227: 'antho',\n",
              " 228: 'anticipate',\n",
              " 229: 'anticipated',\n",
              " 230: 'anticipating',\n",
              " 231: 'anticipation',\n",
              " 232: 'antique',\n",
              " 233: 'antrho',\n",
              " 234: 'antro',\n",
              " 235: 'anxious',\n",
              " 236: 'anxiously',\n",
              " 237: 'anymore',\n",
              " 238: \"anyone's\",\n",
              " 239: 'anytime',\n",
              " 240: 'app',\n",
              " 241: 'appalled',\n",
              " 242: 'apparel',\n",
              " 243: 'apparent',\n",
              " 244: 'apparently',\n",
              " 245: 'appeal',\n",
              " 246: 'appealed',\n",
              " 247: 'appealing',\n",
              " 248: 'appearance',\n",
              " 249: 'appeared',\n",
              " 250: 'appearing',\n",
              " 251: 'appears',\n",
              " 252: 'apple',\n",
              " 253: 'apple-shaped',\n",
              " 254: 'applied',\n",
              " 255: 'appliqu',\n",
              " 256: 'applique',\n",
              " 257: 'apply',\n",
              " 258: 'appreciated',\n",
              " 259: 'apprehensive',\n",
              " 260: 'approach',\n",
              " 261: 'approaching',\n",
              " 262: 'appropriately',\n",
              " 263: 'approved',\n",
              " 264: 'approx',\n",
              " 265: 'approximate',\n",
              " 266: 'approximately',\n",
              " 267: 'apprx',\n",
              " 268: 'apricot',\n",
              " 269: 'april',\n",
              " 270: 'apron',\n",
              " 271: 'apt',\n",
              " 272: 'aqua',\n",
              " 273: 'ar',\n",
              " 274: 'arc',\n",
              " 275: 'area',\n",
              " 276: 'areas',\n",
              " 277: 'aren',\n",
              " 278: 'arielle',\n",
              " 279: 'arm',\n",
              " 280: 'arm-holes',\n",
              " 281: 'armed',\n",
              " 282: 'armhole',\n",
              " 283: 'armholes',\n",
              " 284: 'armpit',\n",
              " 285: 'armpits',\n",
              " 286: 'arms',\n",
              " 287: 'army',\n",
              " 288: 'arranged',\n",
              " 289: 'arrival',\n",
              " 290: 'arrivals',\n",
              " 291: 'arrive',\n",
              " 292: 'arrived',\n",
              " 293: 'arrives',\n",
              " 294: 'arrows',\n",
              " 295: 'art',\n",
              " 296: 'article',\n",
              " 297: 'articles',\n",
              " 298: 'artist',\n",
              " 299: \"artist's\",\n",
              " 300: 'artistic',\n",
              " 301: 'artsy',\n",
              " 302: 'artwork',\n",
              " 303: 'arty-looking',\n",
              " 304: 'as-is',\n",
              " 305: 'as-pictured',\n",
              " 306: 'asap',\n",
              " 307: 'ashley',\n",
              " 308: 'asia',\n",
              " 309: 'asked',\n",
              " 310: 'aspect',\n",
              " 311: 'aspects',\n",
              " 312: 'assessing',\n",
              " 313: 'assets',\n",
              " 314: 'assistance',\n",
              " 315: 'assistant',\n",
              " 316: 'associate',\n",
              " 317: 'associates',\n",
              " 318: 'assume',\n",
              " 319: 'assumed',\n",
              " 320: 'assuming',\n",
              " 321: 'assumption',\n",
              " 322: 'assured',\n",
              " 323: 'astounded',\n",
              " 324: 'asymmetric',\n",
              " 325: 'asymmetrical',\n",
              " 326: 'asymmetry',\n",
              " 327: 'ate',\n",
              " 328: 'athleisure',\n",
              " 329: 'athlete',\n",
              " 330: 'athletic',\n",
              " 331: 'atl',\n",
              " 332: 'atlanta',\n",
              " 333: 'atleast',\n",
              " 334: 'atrocious',\n",
              " 335: 'attach',\n",
              " 336: 'attached',\n",
              " 337: 'attaches',\n",
              " 338: 'attachment',\n",
              " 339: 'attempt',\n",
              " 340: 'attempted',\n",
              " 341: 'attempting',\n",
              " 342: 'attend',\n",
              " 343: 'attendant',\n",
              " 344: 'attended',\n",
              " 345: 'attending',\n",
              " 346: 'attention',\n",
              " 347: 'attire',\n",
              " 348: 'attitude',\n",
              " 349: 'attracted',\n",
              " 350: 'attracting',\n",
              " 351: 'attractive',\n",
              " 352: 'audrey',\n",
              " 353: 'august',\n",
              " 354: 'aunt',\n",
              " 355: 'australian',\n",
              " 356: 'authentic',\n",
              " 357: 'automatically',\n",
              " 358: 'autumn',\n",
              " 359: 'autumnal',\n",
              " 360: 'avail',\n",
              " 361: 'availability',\n",
              " 362: 'average',\n",
              " 363: 'avid',\n",
              " 364: 'avoid',\n",
              " 365: 'avoided',\n",
              " 366: 'avoiding',\n",
              " 367: 'avoids',\n",
              " 368: 'awaited',\n",
              " 369: 'awaiting',\n",
              " 370: 'awards',\n",
              " 371: 'aware',\n",
              " 372: 'awesome',\n",
              " 373: 'awful',\n",
              " 374: 'awhile',\n",
              " 375: 'awkward',\n",
              " 376: 'awkwardly',\n",
              " 377: 'awkwardness',\n",
              " 378: 'az',\n",
              " 379: 'b-c',\n",
              " 380: 'ba',\n",
              " 381: 'babies',\n",
              " 382: 'baby',\n",
              " 383: 'baby-doll',\n",
              " 384: 'babydoll',\n",
              " 385: 'bac',\n",
              " 386: 'bachelorette',\n",
              " 387: 'back-ordered',\n",
              " 388: 'back-up',\n",
              " 389: 'backed',\n",
              " 390: 'background',\n",
              " 391: 'backorder',\n",
              " 392: 'backordered',\n",
              " 393: 'backpack',\n",
              " 394: 'backs',\n",
              " 395: 'backside',\n",
              " 396: 'backup',\n",
              " 397: 'backward',\n",
              " 398: 'backwards',\n",
              " 399: 'backyard',\n",
              " 400: 'bad',\n",
              " 401: 'badly',\n",
              " 402: 'bag',\n",
              " 403: 'bagged',\n",
              " 404: 'baggie',\n",
              " 405: 'baggier',\n",
              " 406: 'bagginess',\n",
              " 407: 'bagging',\n",
              " 408: 'baggy',\n",
              " 409: 'bags',\n",
              " 410: 'bailey',\n",
              " 411: 'baily',\n",
              " 412: 'balance',\n",
              " 413: 'balanced',\n",
              " 414: 'balances',\n",
              " 415: 'balck',\n",
              " 416: 'balked',\n",
              " 417: 'ball',\n",
              " 418: 'ballet',\n",
              " 419: 'balloon',\n",
              " 420: 'ballooned',\n",
              " 421: 'balloons',\n",
              " 422: 'balloony',\n",
              " 423: 'balls',\n",
              " 424: 'bam',\n",
              " 425: 'band',\n",
              " 426: 'bandage',\n",
              " 427: 'bandeau',\n",
              " 428: 'banded',\n",
              " 429: 'banding',\n",
              " 430: 'bands',\n",
              " 431: 'bank',\n",
              " 432: 'bar',\n",
              " 433: 'barbecue',\n",
              " 434: 'bare',\n",
              " 435: 'barefoot',\n",
              " 436: 'barely',\n",
              " 437: 'bargain',\n",
              " 438: 'barley',\n",
              " 439: 'baroque',\n",
              " 440: 'barre',\n",
              " 441: 'barrel',\n",
              " 442: 'base',\n",
              " 443: 'baseball',\n",
              " 444: 'based',\n",
              " 445: 'basic',\n",
              " 446: 'basically',\n",
              " 447: 'basics',\n",
              " 448: 'basis',\n",
              " 449: 'basket',\n",
              " 450: 'basketball',\n",
              " 451: 'basketweave',\n",
              " 452: 'bat',\n",
              " 453: 'batch',\n",
              " 454: 'batches',\n",
              " 455: 'bath',\n",
              " 456: 'bathing',\n",
              " 457: 'bathrobe',\n",
              " 458: 'bathroom',\n",
              " 459: 'battle',\n",
              " 460: 'batwing',\n",
              " 461: 'batwings',\n",
              " 462: 'bay',\n",
              " 463: 'bbq',\n",
              " 464: 'bc',\n",
              " 465: 'bday',\n",
              " 466: 'bea',\n",
              " 467: 'beach',\n",
              " 468: 'beachy',\n",
              " 469: 'bead',\n",
              " 470: 'beaded',\n",
              " 471: 'beading',\n",
              " 472: 'beads',\n",
              " 473: 'beadwork',\n",
              " 474: 'bear',\n",
              " 475: 'beat',\n",
              " 476: 'beauties',\n",
              " 477: 'beautifu',\n",
              " 478: 'beautiful',\n",
              " 479: 'beautifully',\n",
              " 480: 'beautify',\n",
              " 481: 'beauty',\n",
              " 482: 'bec',\n",
              " 483: 'beca',\n",
              " 484: 'becasue',\n",
              " 485: 'becau',\n",
              " 486: 'becaus',\n",
              " 487: 'becuase',\n",
              " 488: 'bed',\n",
              " 489: 'bedtime',\n",
              " 490: 'bee',\n",
              " 491: 'beef',\n",
              " 492: 'bees',\n",
              " 493: 'began',\n",
              " 494: 'begging',\n",
              " 495: 'begin',\n",
              " 496: 'beginning',\n",
              " 497: 'begins',\n",
              " 498: 'behold',\n",
              " 499: 'beige',\n",
              " 500: 'bein',\n",
              " 501: 'bel',\n",
              " 502: 'bell',\n",
              " 503: 'bell-sleeve',\n",
              " 504: 'belled',\n",
              " 505: 'bellow',\n",
              " 506: 'bells',\n",
              " 507: 'belly',\n",
              " 508: 'bellybutton',\n",
              " 509: 'belonged',\n",
              " 510: 'beloved',\n",
              " 511: 'belt',\n",
              " 512: 'belted',\n",
              " 513: 'belting',\n",
              " 514: 'belts',\n",
              " 515: 'bend',\n",
              " 516: 'bending',\n",
              " 517: 'beneath',\n",
              " 518: 'benefit',\n",
              " 519: 'bent',\n",
              " 520: 'bermuda',\n",
              " 521: 'berry',\n",
              " 522: 'bes',\n",
              " 523: 'bet',\n",
              " 524: 'bette',\n",
              " 525: 'betty',\n",
              " 526: 'beware',\n",
              " 527: 'bf',\n",
              " 528: 'bff',\n",
              " 529: 'bi',\n",
              " 530: 'bias',\n",
              " 531: 'biased',\n",
              " 532: 'bib',\n",
              " 533: 'bicep',\n",
              " 534: 'biceps',\n",
              " 535: 'bicycle',\n",
              " 536: 'bid',\n",
              " 537: 'big',\n",
              " 538: 'bigger',\n",
              " 539: 'biggest',\n",
              " 540: 'biggie',\n",
              " 541: 'biggish',\n",
              " 542: 'biker',\n",
              " 543: 'bikini',\n",
              " 544: 'bikinis',\n",
              " 545: 'bill',\n",
              " 546: 'billow',\n",
              " 547: 'billowed',\n",
              " 548: 'billowing',\n",
              " 549: 'billows',\n",
              " 550: 'billowy',\n",
              " 551: 'bind',\n",
              " 552: 'binder',\n",
              " 553: 'binding',\n",
              " 554: 'bingo',\n",
              " 555: 'bird',\n",
              " 556: 'birds',\n",
              " 557: 'birkenstocks',\n",
              " 558: 'birth',\n",
              " 559: 'birthday',\n",
              " 560: 'bit',\n",
              " 561: 'bite',\n",
              " 562: 'bits',\n",
              " 563: 'bitter',\n",
              " 564: 'bizarre',\n",
              " 565: 'bl',\n",
              " 566: 'black',\n",
              " 567: 'black-and',\n",
              " 568: 'blacks',\n",
              " 569: 'blades',\n",
              " 570: 'blah',\n",
              " 571: 'bland',\n",
              " 572: 'blank',\n",
              " 573: 'blanket',\n",
              " 574: 'blankets',\n",
              " 575: 'blazer',\n",
              " 576: 'blazers',\n",
              " 577: 'blazing',\n",
              " 578: 'bleach',\n",
              " 579: 'bleached',\n",
              " 580: 'bled',\n",
              " 581: 'bleed',\n",
              " 582: 'blend',\n",
              " 583: 'blends',\n",
              " 584: 'blessed',\n",
              " 585: 'blight',\n",
              " 586: 'blindly',\n",
              " 587: 'bling',\n",
              " 588: 'blk',\n",
              " 589: 'bloated',\n",
              " 590: 'blob',\n",
              " 591: 'block',\n",
              " 592: 'blocked',\n",
              " 593: 'blocking',\n",
              " 594: 'blocks',\n",
              " 595: 'blog',\n",
              " 596: 'blogger',\n",
              " 597: 'blond',\n",
              " 598: 'blonde',\n",
              " 599: 'blood',\n",
              " 600: 'bloom',\n",
              " 601: 'blossoms',\n",
              " 602: 'blotchy',\n",
              " 603: 'blouse',\n",
              " 604: 'blouse-y',\n",
              " 605: 'bloused',\n",
              " 606: 'blouses',\n",
              " 607: 'blousey',\n",
              " 608: 'blousing',\n",
              " 609: 'blouson',\n",
              " 610: 'blousy',\n",
              " 611: 'blow',\n",
              " 612: 'blown',\n",
              " 613: 'blows',\n",
              " 614: 'blowzy',\n",
              " 615: 'blu',\n",
              " 616: 'blue',\n",
              " 617: 'blue-green',\n",
              " 618: 'blue-grey',\n",
              " 619: 'blue-ish',\n",
              " 620: 'blueish',\n",
              " 621: 'blues',\n",
              " 622: 'bluish',\n",
              " 623: 'bluishgreen',\n",
              " 624: 'blush',\n",
              " 625: 'bo',\n",
              " 626: 'board',\n",
              " 627: 'boarder',\n",
              " 628: 'boardwalk',\n",
              " 629: 'boat',\n",
              " 630: 'boat-neck',\n",
              " 631: 'boatneck',\n",
              " 632: 'bod',\n",
              " 633: 'bodice',\n",
              " 634: 'bodies',\n",
              " 635: 'body',\n",
              " 636: 'body-hugging',\n",
              " 637: 'body-skimming',\n",
              " 638: 'body-type',\n",
              " 639: 'bodycon',\n",
              " 640: 'bodysuit',\n",
              " 641: 'bodytype',\n",
              " 642: 'bog',\n",
              " 643: 'bohemian',\n",
              " 644: 'boho',\n",
              " 645: 'boho-chic',\n",
              " 646: 'boiled',\n",
              " 647: 'bold',\n",
              " 648: 'bolder',\n",
              " 649: 'bolero',\n",
              " 650: 'bomb',\n",
              " 651: 'bomber',\n",
              " 652: 'bomber-style',\n",
              " 653: 'bone',\n",
              " 654: 'boned',\n",
              " 655: 'bones',\n",
              " 656: 'boning',\n",
              " 657: 'bonnet',\n",
              " 658: 'bonus',\n",
              " 659: 'boo',\n",
              " 660: 'boob',\n",
              " 661: 'boobs',\n",
              " 662: 'book',\n",
              " 663: 'books',\n",
              " 664: 'boost',\n",
              " 665: 'boot',\n",
              " 666: 'bootcut',\n",
              " 667: 'bootie',\n",
              " 668: 'booties',\n",
              " 669: 'boots',\n",
              " 670: 'booty',\n",
              " 671: 'bordeaux',\n",
              " 672: 'border',\n",
              " 673: 'bordered',\n",
              " 674: 'borderline',\n",
              " 675: 'borders',\n",
              " 676: 'boring',\n",
              " 677: 'born',\n",
              " 678: 'borrow',\n",
              " 679: 'borrowed',\n",
              " 680: 'bosom',\n",
              " 681: 'boston',\n",
              " 682: 'bot',\n",
              " 683: 'bother',\n",
              " 684: 'bothered',\n",
              " 685: 'bothers',\n",
              " 686: 'bothersome',\n",
              " 687: 'bottom',\n",
              " 688: 'bottom-heavy',\n",
              " 689: 'bottoms',\n",
              " 690: 'bottons',\n",
              " 691: 'boucle',\n",
              " 692: 'bough',\n",
              " 693: 'bounce',\n",
              " 694: 'bouncy',\n",
              " 695: 'bow',\n",
              " 696: 'bows',\n",
              " 697: 'box',\n",
              " 698: 'boxes',\n",
              " 699: 'boxier',\n",
              " 700: 'boxiness',\n",
              " 701: 'boxing',\n",
              " 702: 'boxy',\n",
              " 703: 'boy',\n",
              " 704: 'boyfriend',\n",
              " 705: 'boyfriends',\n",
              " 706: 'boyish',\n",
              " 707: 'boyleg',\n",
              " 708: 'boys',\n",
              " 709: 'br',\n",
              " 710: 'bra',\n",
              " 711: 'bra-less',\n",
              " 712: 'bra-straps',\n",
              " 713: 'bracelet',\n",
              " 714: 'braided',\n",
              " 715: 'brainer',\n",
              " 716: 'braless',\n",
              " 717: 'bralette',\n",
              " 718: 'bralettes',\n",
              " 719: 'branch',\n",
              " 720: 'branches',\n",
              " 721: 'brand',\n",
              " 722: 'brands',\n",
              " 723: 'bras',\n",
              " 724: 'brass',\n",
              " 725: 'break',\n",
              " 726: 'breaker',\n",
              " 727: 'breakers',\n",
              " 728: 'breaking',\n",
              " 729: 'breaks',\n",
              " 730: 'breast',\n",
              " 731: 'breasted',\n",
              " 732: 'breastfeeding',\n",
              " 733: 'breasting',\n",
              " 734: 'breasts',\n",
              " 735: 'breath',\n",
              " 736: 'breathable',\n",
              " 737: 'breathe',\n",
              " 738: 'breathes',\n",
              " 739: 'breathing',\n",
              " 740: 'breathtaking',\n",
              " 741: 'breeze',\n",
              " 742: 'breezy',\n",
              " 743: 'breton',\n",
              " 744: 'brick',\n",
              " 745: 'bridal',\n",
              " 746: 'bride',\n",
              " 747: 'bridesmaid',\n",
              " 748: 'bridesmaids',\n",
              " 749: 'briefly',\n",
              " 750: 'briefs',\n",
              " 751: 'bright',\n",
              " 752: 'brighten',\n",
              " 753: 'brightens',\n",
              " 754: 'brighter',\n",
              " 755: 'brightness',\n",
              " 756: 'brilliant',\n",
              " 757: 'bring',\n",
              " 758: 'bringing',\n",
              " 759: 'brings',\n",
              " 760: 'brioche',\n",
              " 761: 'brisk',\n",
              " 762: 'british',\n",
              " 763: 'broach',\n",
              " 764: 'broad',\n",
              " 765: 'broad-shouldered',\n",
              " 766: 'broaden',\n",
              " 767: 'broadened',\n",
              " 768: 'broader',\n",
              " 769: 'brocade',\n",
              " 770: 'broke',\n",
              " 771: 'broken',\n",
              " 772: 'bronze',\n",
              " 773: 'brooklyn',\n",
              " 774: \"brother's\",\n",
              " 775: 'brought',\n",
              " 776: 'brown',\n",
              " 777: 'brownish',\n",
              " 778: 'browns',\n",
              " 779: 'browse',\n",
              " 780: 'browsing',\n",
              " 781: 'brunch',\n",
              " 782: 'brunette',\n",
              " 783: 'brush',\n",
              " 784: 'brushed',\n",
              " 785: 'brushing',\n",
              " 786: 'bs',\n",
              " 787: 'btu',\n",
              " 788: 'btw',\n",
              " 789: 'bu',\n",
              " 790: 'bubble',\n",
              " 791: 'bubble-like',\n",
              " 792: 'bubbled',\n",
              " 793: 'bubbles',\n",
              " 794: 'buckle',\n",
              " 795: 'buckled',\n",
              " 796: 'buckles',\n",
              " 797: 'bucks',\n",
              " 798: 'budge',\n",
              " 799: 'budget',\n",
              " 800: 'bug',\n",
              " 801: 'bugs',\n",
              " 802: 'build',\n",
              " 803: 'building',\n",
              " 804: 'builds',\n",
              " 805: 'built',\n",
              " 806: 'built-in',\n",
              " 807: 'bulge',\n",
              " 808: 'bulged',\n",
              " 809: 'bulges',\n",
              " 810: 'bulging',\n",
              " 811: 'bulk',\n",
              " 812: 'bulkier',\n",
              " 813: 'bulkiness',\n",
              " 814: 'bulky',\n",
              " 815: 'bullet',\n",
              " 816: 'bum',\n",
              " 817: 'bummed',\n",
              " 818: 'bummer',\n",
              " 819: 'bump',\n",
              " 820: 'bumped',\n",
              " 821: 'bumps',\n",
              " 822: 'bumpy',\n",
              " 823: 'bun',\n",
              " 824: 'bunch',\n",
              " 825: 'bunched',\n",
              " 826: 'bunches',\n",
              " 827: 'bunching',\n",
              " 828: 'bunchy',\n",
              " 829: 'bundle',\n",
              " 830: 'burgers',\n",
              " 831: 'burgundy',\n",
              " 832: 'burlap',\n",
              " 833: 'burn',\n",
              " 834: 'burned',\n",
              " 835: 'burnout',\n",
              " 836: 'burns',\n",
              " 837: 'burnt',\n",
              " 838: 'burst',\n",
              " 839: 'bus',\n",
              " 840: 'business',\n",
              " 841: 'business-casual',\n",
              " 842: 'bust',\n",
              " 843: 'bust-line',\n",
              " 844: 'busted',\n",
              " 845: 'bustier',\n",
              " 846: 'busting',\n",
              " 847: 'bustline',\n",
              " 848: 'busts',\n",
              " 849: 'busty',\n",
              " 850: 'busy',\n",
              " 851: 'butt',\n",
              " 852: 'butter',\n",
              " 853: 'butterflies',\n",
              " 854: 'butterfly',\n",
              " 855: 'buttery',\n",
              " 856: 'button',\n",
              " 857: 'button-down',\n",
              " 858: 'button-front',\n",
              " 859: 'button-up',\n",
              " 860: 'buttondown',\n",
              " 861: 'buttoned',\n",
              " 862: 'buttoned-up',\n",
              " 863: 'buttonhole',\n",
              " 864: 'buttonholes',\n",
              " 865: 'buttoning',\n",
              " 866: 'buttons',\n",
              " 867: 'butts',\n",
              " 868: 'buy',\n",
              " 869: 'buyer',\n",
              " 870: 'buyers',\n",
              " 871: 'buyi',\n",
              " 872: 'buying',\n",
              " 873: 'byron',\n",
              " 874: 'c-cup',\n",
              " 875: 'c-d',\n",
              " 876: 'ca',\n",
              " 877: 'cable',\n",
              " 878: 'cacti',\n",
              " 879: 'cafe',\n",
              " 880: 'caftan',\n",
              " 881: 'cage',\n",
              " 882: 'cake',\n",
              " 883: 'cal',\n",
              " 884: 'calf',\n",
              " 885: 'cali',\n",
              " 886: 'california',\n",
              " 887: 'call',\n",
              " 888: 'called',\n",
              " 889: 'calling',\n",
              " 890: 'calls',\n",
              " 891: 'calves',\n",
              " 892: 'cam',\n",
              " 893: 'camel',\n",
              " 894: 'camera',\n",
              " 895: 'cami',\n",
              " 896: \"cami's\",\n",
              " 897: 'camis',\n",
              " 898: 'camisol',\n",
              " 899: 'camisole',\n",
              " 900: 'camisoles',\n",
              " 901: 'camo',\n",
              " 902: 'camouflage',\n",
              " 903: 'camouflages',\n",
              " 904: 'camouflaging',\n",
              " 905: 'camp',\n",
              " 906: 'campus',\n",
              " 907: 'cancel',\n",
              " 908: 'cancelled',\n",
              " 909: 'cancer',\n",
              " 910: 'canvas',\n",
              " 911: 'canvas-y',\n",
              " 912: 'cap',\n",
              " 913: 'cape',\n",
              " 914: 'capes',\n",
              " 915: 'capped',\n",
              " 916: 'capri',\n",
              " 917: 'capris',\n",
              " 918: 'capsule',\n",
              " 919: 'capture',\n",
              " 920: 'car',\n",
              " 921: 'caramel',\n",
              " 922: 'carbon',\n",
              " 923: 'card',\n",
              " 924: 'cardi',\n",
              " 925: 'cardigan',\n",
              " 926: 'cardigans',\n",
              " 927: 'cardio',\n",
              " 928: 'cardis',\n",
              " 929: 'care',\n",
              " 930: 'carefree',\n",
              " 931: 'careful',\n",
              " 932: 'carefully',\n",
              " 933: 'cares',\n",
              " 934: 'cargo',\n",
              " 935: 'cargos',\n",
              " 936: 'caribbean',\n",
              " 937: 'carissima',\n",
              " 938: 'carpet',\n",
              " 939: 'carried',\n",
              " 940: 'carries',\n",
              " 941: 'carry',\n",
              " 942: 'carrying',\n",
              " 943: 'cart',\n",
              " 944: 'cartonnier',\n",
              " 945: 'cartoon',\n",
              " 946: 'cartoonish',\n",
              " 947: 'cas',\n",
              " 948: 'cascade',\n",
              " 949: 'cascades',\n",
              " 950: 'case',\n",
              " 951: 'cases',\n",
              " 952: 'cash',\n",
              " 953: 'cashier',\n",
              " 954: 'cashmere',\n",
              " 955: 'casing',\n",
              " 956: 'casu',\n",
              " 957: 'casual',\n",
              " 958: 'casually',\n",
              " 959: 'cat',\n",
              " 960: 'catalog',\n",
              " 961: 'catalogue',\n",
              " 962: 'catch',\n",
              " 963: 'catcher',\n",
              " 964: 'catches',\n",
              " 965: 'catching',\n",
              " 966: 'catchy',\n",
              " 967: 'categorized',\n",
              " 968: 'category',\n",
              " 969: 'cats',\n",
              " 970: 'caught',\n",
              " 971: 'causal',\n",
              " 972: 'caused',\n",
              " 973: 'causing',\n",
              " 974: 'caution',\n",
              " 975: 'cautious',\n",
              " 976: 'cave',\n",
              " 977: 'caveat',\n",
              " 978: 'caved',\n",
              " 979: 'cc',\n",
              " 980: 'ceases',\n",
              " 981: 'cedar',\n",
              " 982: 'cehst',\n",
              " 983: 'celadon',\n",
              " 984: 'celebrate',\n",
              " 985: 'celebration',\n",
              " 986: 'cell',\n",
              " 987: 'cellophane',\n",
              " 988: 'cellulite',\n",
              " 989: 'center',\n",
              " 990: 'centered',\n",
              " 991: 'cents',\n",
              " 992: 'ceremony',\n",
              " 993: 'ch',\n",
              " 994: 'chain',\n",
              " 995: 'chair',\n",
              " 996: 'challenge',\n",
              " 997: 'challenged',\n",
              " 998: 'challenges',\n",
              " 999: 'challenging',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create a TF-IDF representation of thee review\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tVectorizer = TfidfVectorizer(analyzer = \"word\",vocabulary = vocab) # initialised the TfidfVectorizer\n",
        "tfidf_features = tVectorizer.fit_transform(joined_reviews) # generate the tfidf vector representation for all articles\n",
        "tfidf_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9Vg2z_2Dbyj",
        "outputId": "7585e92b-0d51-4bc9-eccf-3245ed80f944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19652, 7529)"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def write_vectorFile(data_features,filename):\n",
        "    num = data_features.shape[0] # the number of document\n",
        "    out_file = open(filename, 'w') # creates a txt file and open to save the vector representation\n",
        "    for a_ind in range(0, num): # loop through each article by index\n",
        "        for f_ind in data_features[a_ind].nonzero()[1]: # for each word index that has non-zero entry in the data_feature\n",
        "            value = data_features[a_ind][0,f_ind] # retrieve the value of the entry from data_features\n",
        "            out_file.write(\"{}:{} \".format(f_ind,value)) # write the entry to the file in the format of word_index:value\n",
        "        out_file.write('\\n') # start a new line after each article\n",
        "    out_file.close() # close the file"
      ],
      "metadata": {
        "id": "fdLZxM4nNmdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tVector_file = \"./review_tVector.txt\" # file name of the tfidf vector\n",
        "write_vectorFile(tfidf_features,tVector_file) # write the tfidf vector to file"
      ],
      "metadata": {
        "id": "jz0LLlWCNo5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doc_wordweights (fName_tVectors, voc_dict):\n",
        "  tfidf_weights = []\n",
        "\n",
        "  with open(fName_tVectors) as tVecf:\n",
        "    tVectors = tVecf.read().splitlines()\n",
        "  for tv in tVectors: # for each tfidf document vector\n",
        "    tv = tv.strip()\n",
        "    weights = tv.split(' ') # list of 'word_index:weight' entries\n",
        "    weights = [w.split(':') for w in weights] # list of [word_index, weight] entries\n",
        "    wordweight_dict = {voc_dict[int(w[0])]: w[1] for w in weights} # dictionary of word:weight pairs\n",
        "    tfidf_weights.append(wordweight_dict)\n",
        "  return tfidf_weights\n",
        "\n",
        "fName_tVectors = 'review_tVector.txt' # file name of the tfidf vector\n",
        "tfidf_weights = doc_wordweights(fName_tVectors, voc_dict)"
      ],
      "metadata": {
        "id": "i0hMFpE0xnoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_weights[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nCy3k40xnmB",
        "outputId": "2853f7cc-dbf4-4146-c99b-90a0edb90132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bottom': '0.1049090504878116',\n",
              " 'cheap': '0.1383468173355121',\n",
              " 'design': '0.09819053319703584',\n",
              " 'directly': '0.22042366265962404',\n",
              " 'fact': '0.1468703738136722',\n",
              " 'flaw': '0.18693685782734779',\n",
              " 'found': '0.11016820762903572',\n",
              " 'half': '0.29992142257858667',\n",
              " 'high': '0.10509713403953783',\n",
              " 'hopes': '0.16844705121993464',\n",
              " 'imo': '0.19309847172209632',\n",
              " 'initially': '0.1709779316124002',\n",
              " 'layer': '0.27389678699967074',\n",
              " 'layers': '0.1640176063766487',\n",
              " 'major': '0.19468911285051196',\n",
              " 'medium': '0.09045659947118839',\n",
              " 'net': '0.4867876227942156',\n",
              " 'nicely': '0.11400095142158767',\n",
              " 'outrageously': '0.2567966207221876',\n",
              " 'petite': '0.17993461419688878',\n",
              " 'reordered': '0.20116611478729474',\n",
              " 'sewn': '0.15731076193390783',\n",
              " 'tight': '0.09944270371682067',\n",
              " 'usual': '0.11089799670931574',\n",
              " 'wanted': '0.10688230992054927',\n",
              " 'work': '0.08942754431903752',\n",
              " 'zip': '0.1579093630253308',\n",
              " 'zipper': '0.1379665564316224'}"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_docvecs(embeddings, tfidf, docs):\n",
        "    # Initialize a zero matrix to store document vectors\n",
        "    # Shape: (number of documents, embedding dimension)\n",
        "    vecs = np.zeros((len(docs), embeddings.vector_size))\n",
        "\n",
        "    # Iterate through each document\n",
        "    for i, doc in enumerate(docs):\n",
        "        # Filter out terms that are not in the embedding vocabulary\n",
        "        valid_keys = [term for term in doc if term in embeddings.key_to_index]\n",
        "\n",
        "        # Get TF-IDF weights for valid terms\n",
        "        # If a term is not in the TF-IDF matrix, its weight is set to 0\n",
        "        tf_weights = [float(tfidf[i].get(term, 0.)) for term in valid_keys]\n",
        "\n",
        "        # Ensure that we have the same number of terms and weights\n",
        "        assert len(valid_keys) == len(tf_weights)\n",
        "\n",
        "        # Multiply each term's embedding by its TF-IDF weight\n",
        "        weighted = [embeddings[term] * w for term, w in zip(valid_keys, tf_weights)]\n",
        "\n",
        "        # Stack the weighted embeddings vertically\n",
        "        docvec = np.vstack(weighted)\n",
        "\n",
        "        # Sum up all the weighted embeddings to get the document vector\n",
        "        docvec = np.sum(docvec, axis=0)\n",
        "\n",
        "        # Store the document vector in the results matrix\n",
        "        vecs[i,:] = docvec\n",
        "\n",
        "    return vecs"
      ],
      "metadata": {
        "id": "A2SFCp-AZEU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_docvecs(embeddings, tfidf, docs):\n",
        "    # Initialize a zero matrix to store document vectors\n",
        "    vecs = np.zeros((len(docs), embeddings.vector_size))\n",
        "    for i, doc in enumerate(docs):\n",
        "        # Filter out terms that are not in the embedding vocabulary\n",
        "        valid_keys = [term for term in doc if term in embeddings.key_to_index]\n",
        "        #  Get TF-IDF weights for valid terms\n",
        "        # If a term is not in the TF-IDF matrix, its weight is set to 0\n",
        "        tf_weights = [float(tfidf[i].get(term, 0.)) for term in valid_keys]\n",
        "        assert len(valid_keys) == len(tf_weights)\n",
        "        # Multiply each term's embedding by its TF-IDF weight\n",
        "        weighted = [embeddings[term] * w for term, w in zip(valid_keys, tf_weights)]\n",
        "        # Stack the weighted embeddings vertically\n",
        "        docvec = np.vstack(weighted)\n",
        "        # Sum up all the weighted embeddings to get the document vector\n",
        "        docvec = np.sum(docvec, axis=0)\n",
        "        vecs[i,:] = docvec\n",
        "    return vecs"
      ],
      "metadata": {
        "id": "6mGwAhufxnjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_preTGloVe_dvs = weighted_docvecs(preTGloVe_wv, tfidf_weights, tk_reviews)"
      ],
      "metadata": {
        "id": "Oiodtf8-xnhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_preTGloVe_dvs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QlynoL_xnfF",
        "outputId": "fbde0bdf-41bd-4a40-87ad-b8a4617ea2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.81326997, -1.20487916,  1.61317408, ...,  0.35037398,\n",
              "         0.98145258, -0.72741616],\n",
              "       [-1.02930331,  0.49924228, -2.1061604 , ..., -0.78494704,\n",
              "         0.23018403,  0.64478934],\n",
              "       [-1.99558759,  1.09937561, -0.89829326, ..., -2.16219521,\n",
              "        -0.19498554, -1.36913705],\n",
              "       ...,\n",
              "       [ 0.44179174, -0.32263976, -0.0057269 , ..., -0.63758403,\n",
              "        -0.1635806 ,  1.01626301],\n",
              "       [ 0.66972482,  0.61471367,  0.64147234, ..., -0.52802664,\n",
              "        -0.41661435,  0.86121458],\n",
              "       [ 0.47965372,  0.20797431, -2.14299273, ..., -0.08895668,\n",
              "         0.61969817,  1.32442343]])"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbThQ01NueBT"
      },
      "source": [
        "### **Saving outputs**\n",
        "Save the count vector\n",
        "- count_vectors.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create webindices from Clothing ID\n",
        "webindices = data['Clothing ID'].tolist()"
      ],
      "metadata": {
        "id": "fyIKBio2vEqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write count vectors to file\n",
        "count_vector_file = \"./count_vectors.txt\"\n",
        "write_vectorFile_with_index(count_features, count_vector_file, webindices)"
      ],
      "metadata": {
        "id": "KR3XYXP0vVD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_count_vectors(file_path, num_samples=5):\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()[:num_samples]  # Read only the first 5 lines\n",
        "\n",
        "    print(f\"First {num_samples} lines from {file_path}:\")\n",
        "    for line in lines:\n",
        "        print(line.strip())\n",
        "\n",
        "read_count_vectors('count_vectors.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TifGijP0vgfo",
        "outputId": "399c4458-d09a-431a-95b5-c51ac780a2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 lines from count_vectors.txt:\n",
            "#1077,687:1,1028:1,1716:1,1792:1,2289:1,2481:1,2602:1,2892:2,3010:1,3087:1,3193:1,3258:1,3549:2,3552:1,3832:1,3934:1,4224:2,4234:1,4427:1,4639:2,5260:1,5668:1,6726:1,7092:1,7207:1,7406:1,7520:1,7522:1,\n",
            "#1049,1287:1,2284:1,2502:1,2667:1,3403:1,6739:1,\n",
            "#847,86:1,925:1,1988:1,2646:1,3584:1,3595:1,4506:1,5736:2,5924:1,6716:1,\n",
            "#1080,179:1,721:1,1950:1,2083:1,2373:1,2610:1,2657:1,2711:1,3168:1,3707:1,3748:1,4472:1,4484:1,4639:1,4912:1,5176:1,5332:1,5764:1,5900:2,6290:1,6366:1,6548:1,6809:1,7406:1,\n",
            "#858,408:1,449:1,818:1,1630:1,2050:1,2803:1,3120:4,4363:1,4513:1,4528:1,4628:1,4639:1,4663:1,4883:1,5903:1,6274:1,6601:1,6907:1,7469:1,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GziDkVMIueBT"
      },
      "source": [
        "## Task 3. Clothing Review Classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import issparse"
      ],
      "metadata": {
        "id": "-cvyB3F6aZrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the target variable\n",
        "y = data['Recommended IND'].values"
      ],
      "metadata": {
        "id": "8H-yqwoIamB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform classification and cross-validation\n",
        "def classify_and_evaluate(X, y):\n",
        "    if issparse(X):\n",
        "        # For sparse matrices, we don't need to scale\n",
        "        model = LogisticRegression(random_state=42)\n",
        "    else:\n",
        "        # For dense matrices, we can use StandardScaler\n",
        "        scaler = StandardScaler(with_mean=not issparse(X))\n",
        "        X = scaler.fit_transform(X)\n",
        "        model = LogisticRegression(random_state=42)\n",
        "\n",
        "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "    return np.mean(scores)"
      ],
      "metadata": {
        "id": "Qz5uLIjSakHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Language model comparisons**"
      ],
      "metadata": {
        "id": "khxbX_T-are-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGUNXpjLueBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1465f736-e0c0-4163-b7af-f53046def370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1 Results:\n",
            "Count Vectors Accuracy: 0.8753\n",
            "Binary Vectors Accuracy: 0.8759\n",
            "TF-IDF Vectors Accuracy: 0.8737\n",
            "Weighted Glove Vector Accuracy: 0.8257\n",
            "Unweighted GloVe Vectors Accuracy: 0.8255\n",
            "\n",
            "Q2 Results:\n",
            "Title Only Accuracy: 0.8623\n",
            "Review Text Only Accuracy: 0.8737\n",
            "Combined Title and Review Text Accuracy: 0.8867\n"
          ]
        }
      ],
      "source": [
        "# Count vectors\n",
        "count_accuracy = classify_and_evaluate(count_features, y)\n",
        "\n",
        "# Binary vectors\n",
        "binary_accuracy = classify_and_evaluate(binary_features, y)\n",
        "\n",
        "# TF-IDF vectors\n",
        "tfidf_accuracy = classify_and_evaluate(tfidf_features, y)\n",
        "\n",
        "# Weighted GloVe vectors\n",
        "weighted_glove_accuracy = classify_and_evaluate(weighted_preTGloVe_dvs, y)\n",
        "\n",
        "# Unweighted GloVe vectors\n",
        "unweighted_glove_accuracy = classify_and_evaluate(unweighted_preTGloVe_dvs, y)\n",
        "\n",
        "print(\"Q1 Results:\")\n",
        "print(f\"Count Vectors Accuracy: {count_accuracy:.4f}\")\n",
        "print(f\"Binary Vectors Accuracy: {binary_accuracy:.4f}\")\n",
        "print(f\"TF-IDF Vectors Accuracy: {tfidf_accuracy:.4f}\")\n",
        "print(f\"Weighted Glove Vector Accuracy: {weighted_glove_accuracy:.4f}\")\n",
        "print(f\"Unweighted GloVe Vectors Accuracy: {unweighted_glove_accuracy:.4f}\")\n",
        "\n",
        "# Q2: Checking if better accuracy can be achieved.\n",
        "\n",
        "# Using TF-IDF vectorizer for this example\n",
        "vectorizer = TfidfVectorizer(analyzer=\"word\", vocabulary=vocab)\n",
        "\n",
        "# Only title\n",
        "title_features = vectorizer.fit_transform(data['Title'])\n",
        "title_accuracy = classify_and_evaluate(title_features, y)\n",
        "\n",
        "# Only review text (already done in Q1 with tfidf_accuracy)\n",
        "\n",
        "# Both title and review text\n",
        "combined_text = data['Title'] + \" \" + data['Review Text']\n",
        "combined_features = vectorizer.fit_transform(combined_text)\n",
        "combined_accuracy = classify_and_evaluate(combined_features, y)\n",
        "\n",
        "print(\"\\nQ2 Results:\")\n",
        "print(f\"Title Only Accuracy: {title_accuracy:.4f}\")\n",
        "print(f\"Review Text Only Accuracy: {tfidf_accuracy:.4f}\")\n",
        "print(f\"Combined Title and Review Text Accuracy: {combined_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE5MFpu9ueBT"
      },
      "source": [
        "## Summary\n",
        "\n",
        "* Simpler bag-of-words models outperformed complex representations for this task  \n",
        "* Combining title and review text improved classification accuracy  \n",
        "* High accuracies (>82%) indicate strong predictive signals in the review text  \n",
        "* Feature engineering and multiple information sources are crucial for NLP tasks in e-commerce applications  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference  \n",
        "\n",
        "I have used the functions from the follwoing activities notebook files provided in the RMIT Canvas.  \n",
        "* w07_act1_gen_feat_vec.ipynb\n",
        "* w07_act2_classification.ipynb\n",
        "* w08_act1_term_embedding.ipynb\n",
        "* w08_act2_embedding_classification.ipynb\n"
      ],
      "metadata": {
        "id": "SibQ14Y3eWWS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tOomO3Gp3SAS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}